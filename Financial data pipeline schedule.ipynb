{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27b543c7-ca7b-4e68-8b3e-cb6e64555f5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Updating our data regularly\n",
    "## Bronze layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48d50982-25c4-4938-99d7-e731b52b15ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Getting latest links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a59bac3c-e1ae-4c27-a639-2a7b99a3d34a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sec.gov/files/dera/data/financial-statement-data-sets/2024q2.zip',\n",
       " 'https://www.sec.gov/files/dera/data/financial-statement-data-sets/2024q1.zip']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "now = datetime.now()\n",
    "current_year = now.year\n",
    "current_month = now.month\n",
    "\n",
    "current_quarter = (current_month - 1) // 3 \n",
    "previous_data_quarter = (current_month - 1) // 3 - 1\n",
    "\n",
    "current_needed_data = f'https://www.sec.gov/files/dera/data/financial-statement-data-sets/{current_year}q{current_quarter}.zip'\n",
    "\n",
    "previous_needed_data = f'https://www.sec.gov/files/dera/data/financial-statement-data-sets/{current_year}q{previous_data_quarter}.zip'\n",
    "\n",
    "new_links = [current_needed_data,previous_needed_data]\n",
    "new_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2ecc048-c0a8-4a31-8da3-a2500726eb09",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Updating latest zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcaf8982-6e15-4f9c-9b5c-831f899f2dbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 2024q2.zip already exists in blob storage. Skipping upload.\n",
      "file 2024q1.zip already exists in blob storage. Skipping upload.\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import requests\n",
    "\n",
    "connection_string = \"\"\n",
    "container_name = \"testtech\"\n",
    "headers = {\n",
    "   \"User-Agent\": \"jo boulement jo@gmx.at\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\" \n",
    "}\n",
    "\n",
    "# Initialize BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "def download_to_blob(url, blob_name):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "        \n",
    "        # Check if the blob already exists\n",
    "        if blob_client.exists():\n",
    "            print(f'file {blob_name} already exists in blob storage. Skipping upload.')\n",
    "        else:\n",
    "            # Upload the blob if it doesn't exist\n",
    "            blob_client.upload_blob(response.content, overwrite=True)\n",
    "            print(f'file {blob_name} uploaded to blob storage')\n",
    "    else:\n",
    "        print(f'failed to download from {url}. Status code {response.status_code}')\n",
    "\n",
    "def main():\n",
    "    for url in new_links:\n",
    "        blob_name = url.split('/')[-1]\n",
    "        download_to_blob(url, blob_name)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e786b24b-2ce4-416e-af97-4693d92c75ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Silver Layer\n",
    "\n",
    "### Updating Unzipped Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb925d70-b804-49a6-bc72-c74dc9f536cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '2024q1.zip', 'container': 'testtech', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 7, 14, 19, 53, 9, tzinfo=datetime.timezone.utc), 'etag': '0x8DCA43E96338689', 'size': 56204702, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b'-\"D\\xe9\\xff\\xbc\\xc6\\xf1\\xb8\\x0c\\xa4\\x12\\x8c\\x14+R'), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 7, 14, 19, 53, 9, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None},\n",
       " {'name': '2024q2.zip', 'container': 'testtech', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 7, 14, 19, 53, 8, tzinfo=datetime.timezone.utc), 'etag': '0x8DCA43E958ABD9B', 'size': 53821685, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b'\\x07\\xf2o\\xae4\\xe6\\x16\\xecd\\xc6\\xf0\\x81\\xa5=s\\xf6'), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 7, 14, 19, 53, 8, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None},\n",
       " {'name': 'temp_folder/num.txt', 'container': 'testtech', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 7, 14, 20, 20, 29, tzinfo=datetime.timezone.utc), 'etag': '0x8DCA44267BD275B', 'size': 281651546, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': None, 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 7, 8, 1, 42, 2, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None},\n",
       " {'name': 'temp_folder/pre.txt', 'container': 'testtech', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 7, 14, 20, 20, 27, tzinfo=datetime.timezone.utc), 'etag': '0x8DCA442667F0799', 'size': 158347105, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': None, 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 7, 8, 1, 42, 2, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None},\n",
       " {'name': 'temp_folder/readme.htm', 'container': 'testtech', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 7, 14, 20, 20, 29, tzinfo=datetime.timezone.utc), 'etag': '0x8DCA44267F363CB', 'size': 152080, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b'\\xf1jp\\x16\\xdc!S\\xbd\\xe9\\xa4M\\x9f\\x89#fG'), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 7, 8, 1, 42, 3, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None},\n",
       " {'name': 'temp_folder/sub.txt', 'container': 'testtech', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 7, 14, 20, 20, 26, tzinfo=datetime.timezone.utc), 'etag': '0x8DCA44265C0ABF9', 'size': 8708445, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': None, 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 7, 8, 1, 42, 1, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None},\n",
       " {'name': 'temp_folder/tag.txt', 'container': 'testtech', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 7, 14, 20, 20, 29, tzinfo=datetime.timezone.utc), 'etag': '0x8DCA44267F00C3B', 'size': 24789454, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': None, 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 7, 8, 1, 42, 1, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Function to get blobs uploaded within the last 'n' minutes\n",
    "def get_recent_blobs(container_client, minutes):\n",
    "    # Calculate the time threshold\n",
    "    threshold_time = datetime.now(timezone.utc) - timedelta(minutes=minutes)\n",
    "\n",
    "    # List all blobs in the container\n",
    "    blobs = container_client.list_blobs()\n",
    "\n",
    "    # Filter blobs based on the 'last_modified' time\n",
    "    recent_blobs = [blob for blob in blobs if blob.last_modified >= threshold_time]\n",
    "\n",
    "    return recent_blobs\n",
    "\n",
    "# Get blobs uploaded within the last 10 minutes\n",
    "recent_blobs = get_recent_blobs(container_client, 10)\n",
    "\n",
    "recent_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c11c86-f5e2-46e3-a13f-93559d7c5850",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_account_name = \"testtech\"\n",
    "storage_account_key = ''\n",
    "container_name_source = \"testtech\"\n",
    "container_name_dest = \"newtesttech\"\n",
    "\n",
    "\n",
    "# Configure the spark context with the storage account key\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\", storage_account_key)\n",
    "\n",
    "# Mount your source container\n",
    "dbutils.fs.mount(\n",
    "  source = f\"wasbs://{container_name_source}@{storage_account_name}.blob.core.windows.net\",\n",
    "  mount_point = f\"/mnt/{container_name_source}\",\n",
    "  extra_configs = {f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\": storage_account_key}\n",
    ")\n",
    "\n",
    "# Mount your destination container\n",
    "dbutils.fs.mount(\n",
    "  source = f\"wasbs://newtesttech@{storage_account_name}.blob.core.windows.net/\",\n",
    "  mount_point = \"/mnt/newtesttech\",\n",
    "  extra_configs = {f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\": storage_account_key}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a981037-df9f-433c-81a0-400f19404dba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FileInfo(path='dbfs:/mnt/testtech/2024q1.zip', name='2024q1.zip', size=56204702, modificationTime=1720986789000), FileInfo(path='dbfs:/mnt/testtech/2024q2.zip', name='2024q2.zip', size=53821685, modificationTime=1720986788000)]\n",
      "Data upload completed for recent zip files.\n",
      "/mnt/testtech has been unmounted.\n",
      "/mnt/newtesttech has been unmounted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import zipfile\n",
    "\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name_source)\n",
    "\n",
    "# Function to get blobs uploaded within the last 'n' minutes\n",
    "def get_recent_blobs(container_client, minutes):\n",
    "    threshold_time = datetime.now(timezone.utc) - timedelta(minutes=minutes)\n",
    "    blobs = container_client.list_blobs()\n",
    "    recent_blobs = [blob for blob in blobs if blob.last_modified >= threshold_time]\n",
    "    return recent_blobs\n",
    "\n",
    "# Get blobs uploaded within the last 10 minutes\n",
    "recent_blobs = get_recent_blobs(container_client, 10)\n",
    "recent_blob_names = {blob.name for blob in recent_blobs}\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"ProcessZipFiles\").getOrCreate()\n",
    "\n",
    "# Process only recent zip files\n",
    "zip_files = dbutils.fs.ls(f\"/mnt/{container_name_source}\")\n",
    "zip_files = [f for f in zip_files if f.name.endswith('.zip') and f.name in recent_blob_names]\n",
    "print(zip_files)\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    new_folder_name = zip_file.name.split('.')[0]\n",
    "    dbutils.fs.mkdirs(f\"/mnt/{container_name_dest}/{new_folder_name}\")\n",
    "    \n",
    "    extract_path = f'/dbfs/mnt/{container_name_source}/temp_folder'\n",
    "    working_dir = f'/dbfs/mnt/{container_name_source}/{new_folder_name}.zip'\n",
    "    dbutils.fs.mkdirs(extract_path)\n",
    "    \n",
    "    with zipfile.ZipFile(working_dir, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    \n",
    "    sub_path = f'/mnt/{container_name_source}/temp_folder/sub.txt'\n",
    "    sub_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(sub_path)\n",
    "    sub_df = sub_df.withColumn(\"filed\", to_date(col(\"filed\"), \"yyyyMMdd\")).withColumn(\"period\", to_date(col(\"period\"), \"yyyyMMdd\"))\n",
    "    sub_df.write.mode(\"overwrite\").parquet(f'/mnt/{container_name_dest}/{new_folder_name}/sub.parquet')\n",
    "    \n",
    "    tag_path = f'/mnt/{container_name_source}/temp_folder/tag.txt'\n",
    "    tag_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(tag_path)\n",
    "    tag_df.write.mode(\"overwrite\").parquet(f'/mnt/{container_name_dest}/{new_folder_name}/tag.parquet')\n",
    "    \n",
    "    num_path = f'/mnt/{container_name_source}/temp_folder/num.txt'\n",
    "    num_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(num_path)\n",
    "    num_df = num_df.withColumn(\"ddate\", to_date(col(\"ddate\"), \"yyyyMMdd\"))\n",
    "    num_df.write.mode(\"overwrite\").parquet(f'/mnt/{container_name_dest}/{new_folder_name}/num.parquet')\n",
    "    \n",
    "    pre_path = f'/mnt/{container_name_source}/temp_folder/pre.txt'\n",
    "    pre_df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(pre_path)\n",
    "    pre_df.write.mode(\"overwrite\").parquet(f'/mnt/{container_name_dest}/{new_folder_name}/pre.parquet')\n",
    "    \n",
    "    dbutils.fs.rm(extract_path, recurse=True)\n",
    "\n",
    "print(\"Data upload completed for recent zip files.\")\n",
    "\n",
    "# Unmount the containers\n",
    "dbutils.fs.unmount(f\"/mnt/{container_name_source}\")\n",
    "dbutils.fs.unmount(f\"/mnt/{container_name_dest}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebf4bbf6-0e7d-465f-8293-b8118f42b06b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mount(\n",
    "  source = f\"wasbs://newtesttech@{storage_account_name}.blob.core.windows.net/\",\n",
    "  mount_point = \"/mnt/newtesttech\",\n",
    "  extra_configs = {f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\": storage_account_key}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b188649e-8c84-4b30-9904-d309b4a2a6b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Gold layer\n",
    "### Updating database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a5f62c-801f-4272-9f5a-9b865d6ba9f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List all folders in the root directory\n",
    "root_directory = f\"/mnt/{container_name_dest}\"\n",
    "\n",
    "# Function to get folders updated within the last 'n' minutes\n",
    "def get_recently_updated_folders(folders, minutes):\n",
    "    threshold_time = datetime.now(timezone.utc) - timedelta(minutes=minutes)\n",
    "    recently_updated_folders = [folder for folder in folders if folder.modificationTime >= threshold_time.timestamp() * 1000]  # Convert to milliseconds\n",
    "    return recently_updated_folders\n",
    "\n",
    "\n",
    "recently_updated_folders = get_recently_updated_folders(dbutils.fs.ls(root_directory), 10)\n",
    "\n",
    "# Define schemas for each table\n",
    "submissions_schema = StructType([\n",
    "    StructField(\"adsh\", StringType(), False),\n",
    "    StructField(\"cik\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"sic\", IntegerType(), True),\n",
    "    StructField(\"countryba\", StringType(), False),\n",
    "    StructField(\"stprba\", StringType(), True),\n",
    "    StructField(\"cityba\", StringType(), False),\n",
    "    StructField(\"zipba\", StringType(), True),\n",
    "    StructField(\"bas1\", StringType(), True),\n",
    "    StructField(\"bas2\", StringType(), True),\n",
    "    StructField(\"baph\", StringType(), True),\n",
    "    StructField(\"countryma\", StringType(), True),\n",
    "    StructField(\"stprma\", StringType(), True),\n",
    "    StructField(\"cityma\", StringType(), True),\n",
    "    StructField(\"zipma\", StringType(), True),\n",
    "    StructField(\"mas1\", StringType(), True),\n",
    "    StructField(\"mas2\", StringType(), True),\n",
    "    StructField(\"countryinc\", StringType(), False),\n",
    "    StructField(\"stprinc\", StringType(), True),\n",
    "    StructField(\"ein\", StringType(), True),\n",
    "    StructField(\"former\", StringType(), True),\n",
    "    StructField(\"changed\", DateType(), True),\n",
    "    StructField(\"afs\", StringType(), True),\n",
    "    StructField(\"wksi\", BooleanType(), False),\n",
    "    StructField(\"fye\", StringType(), False),\n",
    "    StructField(\"form\", StringType(), False),\n",
    "    StructField(\"period\", DateType(), False),\n",
    "    StructField(\"fy\", IntegerType(), False),\n",
    "    StructField(\"fp\", StringType(), False),\n",
    "    StructField(\"filed\", DateType(), False),\n",
    "    StructField(\"accepted\", TimestampType(), False),\n",
    "    StructField(\"prevrpt\", BooleanType(), False),\n",
    "    StructField(\"detail\", BooleanType(), False),\n",
    "    StructField(\"instance\", StringType(), False),\n",
    "    StructField(\"nciks\", IntegerType(), False),\n",
    "    StructField(\"aciks\", StringType(), True)\n",
    "])\n",
    "\n",
    "tags_schema = StructType([\n",
    "    StructField(\"tag\", StringType(), False),\n",
    "    StructField(\"version\", StringType(), False),\n",
    "    StructField(\"custom\", IntegerType(), False),\n",
    "    StructField(\"abstract\", BooleanType(), False),\n",
    "    StructField(\"datatype\", StringType(), True),\n",
    "    StructField(\"iord\", StringType(), True),\n",
    "    StructField(\"crdr\", StringType(), True),\n",
    "    StructField(\"tlabel\", StringType(), True),\n",
    "    StructField(\"doc\", StringType(), True)\n",
    "])\n",
    "\n",
    "numbers_schema = StructType([\n",
    "    StructField(\"adsh\", StringType(), True),\n",
    "    StructField(\"tag\", StringType(), True),\n",
    "    StructField(\"version\", StringType(), True),\n",
    "    StructField(\"ddate\", DateType(), True),\n",
    "    StructField(\"qtrs\", IntegerType(), True),\n",
    "    StructField(\"uom\", StringType(), True),\n",
    "    StructField(\"coreg\", StringType(), True),\n",
    "    StructField(\"value\", DecimalType(28,4), True),\n",
    "    StructField(\"footnote\", StringType(), True)\n",
    "])\n",
    "\n",
    "presentations_schema = StructType([\n",
    "    StructField(\"adsh\", StringType(), False),\n",
    "    StructField(\"report\", IntegerType(), True),\n",
    "    StructField(\"line\", IntegerType(), False),\n",
    "    StructField(\"stmt\", StringType(), False),\n",
    "    StructField(\"inpth\", BooleanType(), False),\n",
    "    StructField(\"rfile\", StringType(), False),\n",
    "    StructField(\"tag\", StringType(), False),\n",
    "    StructField(\"version\", StringType(), False),\n",
    "    StructField(\"plabel\", StringType(), False)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Function to process files in a specific quarter folder\n",
    "def process_quarter_folder(folder_path):\n",
    "\n",
    "    files = dbutils.fs.ls(folder_path)\n",
    "    for file in files:\n",
    "        if file.name == 'pre.parquet/':\n",
    "            file_path = file.path\n",
    "            df = spark.read.parquet(file_path)\n",
    "            for field in presentations_schema.fields:\n",
    "                df = df.withColumn(field.name, col(field.name).cast(field.dataType))\n",
    "            df.write.mode(\"append\").saveAsTable('Presentations')\n",
    "        elif file.name == 'num.parquet/':\n",
    "            file_path = file.path\n",
    "            df = spark.read.parquet(file_path)\n",
    "            for field in numbers_schema.fields:\n",
    "                df = df.withColumn(field.name, col(field.name).cast(field.dataType))\n",
    "            df.write.mode(\"append\").saveAsTable('Numbers')\n",
    "\n",
    "        elif file.name == 'sub.parquet/':\n",
    "            file_path = file.path\n",
    "            df = spark.read.parquet(file_path)\n",
    "            for field in submissions_schema.fields:\n",
    "                df = df.withColumn(field.name, col(field.name).cast(field.dataType))\n",
    "            df.write.mode(\"append\").saveAsTable('Submissions')\n",
    "\n",
    "        elif file.name == 'tag.parquet/':\n",
    "            file_path = file.path\n",
    "            df = spark.read.parquet(file_path)\n",
    "            for field in tags_schema.fields:\n",
    "                df = df.withColumn(field.name, col(field.name).cast(field.dataType))\n",
    "            df.write.mode(\"append\").saveAsTable('Tags')\n",
    "        else:\n",
    "            print(f\"Skipping file {file.name} as it doesn't match any known pattern\")\n",
    "\n",
    "\n",
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n",
    "\n",
    "def process_recently_updated_quarters():\n",
    "    for quarter in recently_updated_folders:\n",
    "        print(f\"Processing folder: {quarter.name}\")\n",
    "        process_quarter_folder(quarter.path)\n",
    "\n",
    "process_recently_updated_quarters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66990ec3-f91c-435c-86de-6e18fd99ef39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.unmount(f\"/mnt/{container_name_dest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74c2bdb4-8b7f-4e35-867e-ae151e771147",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>5709476</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         5709476
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 80
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT count(*) FROM Numbers;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3461667262514949,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Financial data pipeline schedule",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
